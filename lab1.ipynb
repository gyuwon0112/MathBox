{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab1.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMbGJvsyqsnA1cHEfcjT8Kb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gyuwon0112/MathBox/blob/main/lab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pcd9YDvjVHMo"
      },
      "source": [
        "#!pip install beautifulsoup4\n",
        "#!pip install -U selenium\n",
        "#!apt install chromium-chromedriver\n",
        "#!pip install webdriver-manager\n",
        "!pip install kora -q\n",
        "\n",
        "from kora.selenium import wd\n",
        "from bs4 import BeautifulSoup as bs\n",
        "from time import sleep\n",
        "import random\n",
        "import urllib.request as ur\n",
        "import pandas as pd\n",
        "\n",
        "Course = []\n",
        "Duration = []\n",
        "Start_Date = []\n",
        "Offered_By = []\n",
        "No_Of_Reviews = []\n",
        "rat = []\n",
        "t = []\n",
        "\n",
        "m = 1# page 수\n",
        "\n",
        "while m < (subject/15 + 1): # page까지의 정보 스크랩\n",
        "    if m == 1 : # 첫 page의 url\n",
        "        url = 'https://www.classcentral.com/subject/data-science' \n",
        "    else : # 두번째 page부터는 뒤를 수정해서 page만 넣어주면 됨\n",
        "        url = 'https://www.classcentral.com/subject/data-science?page=%d'%m\n",
        "    \n",
        "    #print(url)\n",
        "\n",
        "    html = bs(ur.urlopen(url).read(), \"html.parser\")\n",
        "    \n",
        "    \n",
        "    #wd.get(url)\n",
        "    #html = BeautifulSoup(wd.page_source)\n",
        "    #html = bs(ur.urlopen(url).read(), 'html.parser')\n",
        "\n",
        "\n",
        "    def find_1st(string, substring):\n",
        "        return string.find(substring, string.find(substring))\n",
        "        \n",
        "    def find_2nd(string, substring):\n",
        "        return string.find(substring, string.find(substring) + 1)\n",
        "\n",
        "    # Course\n",
        "    for i in html.findAll(\"h2\", {\"class\" : \"text-1 weight-semi line-tight margin-bottom-xxsmall\"}):\n",
        "        b = str(i)\n",
        "        #print(b[find_1st(b,'>')+1:find_2nd(b,'<')])\n",
        "        Course.append(b[find_1st(b,'>')+1:find_2nd(b,'<')])\n",
        "          \n",
        "\n",
        "    #print(Course)\n",
        "    course = []\n",
        "    for i in Course:\n",
        "        i = i.strip() # The strip() method removes any leading and trailing characters\n",
        "                    # (space is the default leading character to remove)\n",
        "        #print(i)\n",
        "        course.append(i)\n",
        "        \n",
        "\n",
        "    #print(course)\n",
        "\n",
        "    # Provider/Offered By:\n",
        "    for i in html.findAll('a',href=True, attrs={'class':'hover-underline color-charcoal text-3 margin-left-small line-tight'}):\n",
        "        b = str(i)\n",
        "        #print(b[find_1st(b,'>')+1:find_2nd(b,'<')])\n",
        "        Offered_By.append(b[find_1st(b,'>')+1:find_2nd(b,'<')])\n",
        "    \n",
        "    provider = []\n",
        "    for i in Offered_By:\n",
        "        i = i.strip()\n",
        "        provider.append(i)\n",
        "\n",
        "    #print(provider)\n",
        "\n",
        "    # Ratings\n",
        "    for d in html.findAll('span', attrs={'role':'img', 'class':'cmpt-rating-medium '}):\n",
        "        rat.append(d.get('aria-label'))\n",
        "\n",
        "    Rating = []\n",
        "    for i in rat:\n",
        "        i = i.strip()\n",
        "        #print(i)\n",
        "        Rating.append(i)\n",
        "\n",
        "\n",
        "\n",
        "    #print(Rating)\n",
        "\n",
        "    # Num of Reviews\n",
        "    for i in html.findAll(\"span\", attrs={'class':'text-3 color-gray margin-left-xxsmall'}):\n",
        "        b = str(i)\n",
        "        if i is not None :\n",
        "            No_Of_Reviews.append(i.text)\n",
        "        else:\n",
        "            No_Of_Reviews.append('-1')\n",
        "            \n",
        "        #print(b[find_1st(b,'>')+1:find_2nd(b,'<')])\n",
        "        #No_Of_Reviews.append(b[find_1st(b,'>')+1:find_2nd(b,'<')])\n",
        "    num_reviews = []\n",
        "    for i in No_Of_Reviews:\n",
        "        i = i.strip()\n",
        "        #print(i)\n",
        "        num_reviews.append(i)\n",
        "        \n",
        "    #print(num_reviews)\n",
        "\n",
        "    for d in html.findAll('li', attrs={'class':'nowrap padding-xsmall border-top border-gray-light row horz-align-left'}):\n",
        "        abc = d.find('span', attrs={'aria-label':'Workload and duration'})\n",
        "        if abc is not None:\n",
        "            #print(abc.text)\n",
        "            t.append(abc.text)\n",
        "            \n",
        "    duration = []\n",
        "    for i in t:\n",
        "        i = i.strip()\n",
        "        #print(i)\n",
        "        duration.append(i)\n",
        "\n",
        "    m = m + 1 # 페이지 넘기기\n",
        "\n",
        "    if(len(num_reviews)!=len(course)):\n",
        "        for p in range(len(course)-len(num_reviews)) :\n",
        "            num_reviews.append(-1)\n",
        "    \n",
        "    #print(len(course), len(Rating), len(num_reviews), len(provider), len(duration))\n",
        "    \n",
        "\n",
        "\n",
        "# 원하는 페이지까지 스크롤링한 후 출력한다\n",
        "dfDS = pd.DataFrame({'course':course, 'ratings':Rating,'No_of_Reviews':num_reviews,'provider':provider, 'Duration':duration})\n",
        "dfDS\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpN_97QgQduJ"
      },
      "source": [
        "##3. 본 데이터로부터 얻을 수 있는 정보\n",
        "\n",
        "* 본 프로젝트에서는 훌륭한 데이터 과학 교육과정을 찾기 위해 [Class Central](https://www.classcentral.com/subject/data-science)이라고 불리는 홈페이지를  스크랩 한 것이다.\n",
        "\n",
        "* 이 홈페이지에는 '컴퓨터과학', '비지니스', '엔지니어', '교육' 등 다양한 토픽의 온라인 교육과정을 보여주고 있다. \n",
        "\n",
        "* 본 프로젝트에서는 '데이터과학'과 관련된 정보를 스크랩하였다.\n",
        "\n",
        "* 스크랩한 데이터에는 '강의명', '제공자', '평가', '리뷰', '기간'의 정보가 포함되어 있다.\n",
        "    * '리뷰' : 리뷰 수가 아닌 '-1'로 표기된 강의들은 리뷰가 등록되지 않은 신설 강의에 해당한다\n",
        "    * '기간' : 주당 지정된 시간만큼 학습 할 경우, 몇 주만에 끝낼 수 있는 지에 대한 정보를 제공한다."
      ]
    }
  ]
}